{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import random\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels into numpy array\n",
    "path = 'E:\\whistle_identification\\DOLPHI\\labels_2_48kHz.mat'\n",
    "mat_content = scipy.io.loadmat(path)\n",
    "\n",
    "labels = mat_content['labels']\n",
    "newLabels = []\n",
    "for index,i in enumerate(labels):\n",
    "    newLabels.append(i[0])\n",
    "    \n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\labels48kHz.npy',newLabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "\n",
    "imagesDir = 'E:\\whistle_identification\\DOLPHI\\images48kHz'\n",
    "images = os.listdir(imagesDir)\n",
    "labels1 = np.load('E:\\whistle_identification\\DOLPHI\\\\labels48kHz.npy')\n",
    "labels1 = labels1.astype(np.int32) \n",
    "normImages = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder label vector according to the order in which image files are read via 'os.listdir()'\n",
    "labels = [0]*len(images)\n",
    "\n",
    "for i,image in enumerate(images):\n",
    "    index = image.split('r')[1]\n",
    "    index = index.split('.')[0]\n",
    "    index = int(index)-1\n",
    "    labels[i] = labels1[index]\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrolls through image vectors for normalizing and resizing images\n",
    "\n",
    "for image in images:\n",
    "    \n",
    "    img = Image.open(os.path.join(imagesDir,image))\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, axis = 2)\n",
    "    img_array = np.repeat(img_array,3, axis = 2)\n",
    "    img_normalized = img_array/255.0\n",
    "    img_normalized = img_normalized.astype(np.float32)\n",
    "    normImages.append(img_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balancing\n",
    "\n",
    "print('Class balancing...')\n",
    "X = []\n",
    "y = []\n",
    "positivi = 0 \n",
    "negativi = 0 \n",
    "\n",
    "for ind,y1 in enumerate(labels):\n",
    "    if y1 != 0 :\n",
    "        positivi = positivi + 1\n",
    "        X.append(normImages[ind])\n",
    "        y.append(y1)\n",
    "\n",
    "\n",
    "for index,y2 in enumerate(labels):\n",
    "\n",
    "    if negativi<positivi and y2 == 0:\n",
    "        X.append(normImages[index])\n",
    "        y.append(y2)\n",
    "        negativi = negativi + 1\n",
    "    elif negativi == positivi:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shuffling\n",
    "\n",
    "combined = list(zip(X,y))\n",
    "random.shuffle(combined)\n",
    "\n",
    "X, y = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division into training and testing set\n",
    "\n",
    "lengthX = len(X)\n",
    "lengthY = len(y)\n",
    "\n",
    "\n",
    "rest_X = X[int(lengthX * 0.9):]\n",
    "X_train= X[:int(lengthX * 0.9)]\n",
    "X_train_tot= np.array(X_train)\n",
    "rest_y = y[int(lengthY * 0.9):]\n",
    "y_train = y[:int(lengthY * 0.9)]     \n",
    "y_train_tot = np.array(y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross Validation\n",
    "\n",
    "#####################################################################################\n",
    "# Model definition\n",
    "print('Definizione modello...')\n",
    "model = Sequential()\n",
    "\n",
    "# Adding Convolutional and Max Pooling Layers\n",
    "model.add(Conv2D(32, (7, 7), strides=(2, 2), activation='relu', input_shape=(224,223,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), strides=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Data flattening\n",
    "model.add(Flatten()) \n",
    "\n",
    "# Adding Fully Connected layers\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model build\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "###################################################################################\n",
    "\n",
    "\"\"\" X = np.load('E:\\whistle_identification\\DOLPHI\\\\total_trainX.npy',allow_pickle=True)\n",
    "y = np.load('E:\\whistle_identification\\DOLPHI\\\\total_trainY.npy',allow_pickle=True) \"\"\"\n",
    "X = X_train_tot\n",
    "y = y_train_tot\n",
    "\n",
    "k = 5  # Number of folds\n",
    "stratified_kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_fold = None\n",
    "fold = 1\n",
    "for train_index, val_index in stratified_kfold.split(X, y):\n",
    "    print(f\"Fold: {fold}\")\n",
    "    \n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validate model\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred1 = []\n",
    "    for i in y_pred:\n",
    "        if i[0]>= 0.5:\n",
    "            y_pred1.append(1)\n",
    "        else:\n",
    "            y_pred1.append(0)\n",
    "\n",
    "    y_pred1 = np.array(y_pred1)\n",
    " \n",
    "    accuracy = accuracy_score(y_val, y_pred1)\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_fold = (X_train, X_val, y_train, y_val)\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best fold: {best_fold}\")\n",
    "\n",
    "# Save training and validation data for Vanilla CNN as '.npy' files\n",
    "\"\"\" np.save('E:\\whistle_identification\\DOLPHI\\\\trainImages_vanilla_48kHz.npy', best_fold[0])\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\trainLabels_vanilla_48kHz.npy', best_fold[2])\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\valImages_vanilla_48kHz.npy', best_fold[1])\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\valLabels_vanilla_48kHz.npy', best_fold[3]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross Validation\n",
    "\n",
    "#####################################################################################\n",
    "# Model definition\n",
    "\n",
    "img_width,img_height = 224,223\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the weights of the VGG16\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add fully connected layers at the end of the model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Model build\n",
    "# Model build\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "###################################################################################\n",
    "\n",
    "\"\"\" X = np.load('E:\\whistle_identification\\DOLPHI\\\\total_trainX.npy',allow_pickle=True)\n",
    "y = np.load('E:\\whistle_identification\\DOLPHI\\\\total_trainY.npy',allow_pickle=True) \"\"\"\n",
    "X = X_train_tot\n",
    "y = y_train_tot\n",
    "\n",
    "k = 5  # Number of folds\n",
    "stratified_kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_fold = None\n",
    "fold = 1\n",
    "for train_index, val_index in stratified_kfold.split(X, y):\n",
    "    print(f\"Fold: {fold}\")\n",
    "    \n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validate model\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred1 = []\n",
    "    for i in y_pred:\n",
    "        if i[0]>= 0.5:\n",
    "            y_pred1.append(1)\n",
    "        else:\n",
    "            y_pred1.append(0)\n",
    "\n",
    "    y_pred1 = np.array(y_pred1)\n",
    " \n",
    "    accuracy = accuracy_score(y_val, y_pred1)\n",
    "    \n",
    "    print(f\"Validation Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_fold = (X_train, X_val, y_train, y_val)\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best fold: {best_fold}\")\n",
    "\n",
    "# Save training and validation data for VGG16 as '.npy' files\n",
    "\"\"\" np.save('E:\\whistle_identification\\DOLPHI\\\\trainImages_vgg_48kHz.npy', best_fold[0])\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\trainLabels_vgg_48kHz.npy', best_fold[2])\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\valImages_vgg_48kHz.npy', best_fold[1])\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\valLabels_vgg_48kHz.npy', best_fold[3]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data as '.npy' files\n",
    "\n",
    "\"\"\" np.save('E:\\whistle_identification\\DOLPHI\\\\testX48kHz.npy', rest_X)\n",
    "np.save('E:\\whistle_identification\\DOLPHI\\\\testY48kHz.npy', rest_y) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolphin-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
